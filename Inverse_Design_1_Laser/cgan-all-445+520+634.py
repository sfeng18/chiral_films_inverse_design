import time
import torch
import torch.nn as nn
from torch.nn import functional as F
import spectrum as sp
import numpy as np
import random
from torch.utils.data import DataLoader
import torch.utils.data
from torchvision import utils, datasets, transforms
import math
import csv
import matplotlib
matplotlib.use('TkAgg') 
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from random import randint
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import normalize
from IPython.display import HTML
import matplotlib

batch_size = 16 # Batch size during training
num_epochs =300 # Training times
lr = 0.0001  # optimizer learning rate
beta1 = 0.9  # Beta1 hyperparameters of the Adam optimizer
ngpu = 1  # The number of available GPUs, use 0 to run in CPU mode.
p=0.00001
G_IN_din=4
col_max,col_min=1.806,0.04
thick_max,thick_min=80.0,17.0
str_max,str_min=267.0,20.0
gra_max,gra_min=8.0,1.0
thick_list=[17,30,48,60,80]
str_list=[20,30,40,53,67,80,100,120,133,167,200,233,267]
gra_list=[1,2,3,4,5,6]
torch.manual_seed(0)#Set a random seed to reproduce experimental results.
#Import Data
Color_Dict = {'蓝2': 'blue2', '蓝6': 'blue6', '蓝71': 'blue71','刚果红':'congo red','绿':'green','橘红':'orange','紫':'purple','红':'red','台盼蓝':'tai','黄':'yellow'}
Color_Values=['yellow','orange','congo red','red','purple','tai','blue2','blue6','blue71','green']
NColors =10

'''Change the value of wave1 and wave2'''
wave1=445.0
wave2=520.0
gdif=3.0

scaler = MinMaxScaler(feature_range=(0, 1))
def minmaxscaler(data,max,min):   #MinMaxScaler normalization method
    a=(data - min)/(max-min)
    return a
def inverse_minmaxscaler(data,max,min):#denormalization function
    d=data*(max-min)+min
    return d

def getData1( sdb_statistics_file):#Read real data, full-band, the first four dimensions are color (expressed by 1, 2, 3, etc.), thickness, stretching degree, grayscale, and the last 121 dimensions are full-band G value
    sdb_statistics = sp.read_file(sdb_statistics_file)
    a={}#储存data
    realdata=[]
    for index,cl in enumerate(Color_Values):
        x1 = [] #Store data of color, angle, thickness, degree of stretching, and grayscale
        for key in sdb_statistics.keys():
            sdb_statistics_key = key.split('-')
            if sdb_statistics_key[0] == cl:
                x1.append(index+1)
                for j in range(3,6):
                    x1.append(float(sdb_statistics_key[j]))
                for index1,value in enumerate(sdb_statistics[key]['X']):
                    if value == 445.0:
                        k = index1
                    if value ==520.0:
                        y=index1
                    if value == 634.0:
                        e=index1
                x1.append(sdb_statistics[key]['G'][k])
                x1.append(sdb_statistics[key]['G'][y])
                x1.append(sdb_statistics[key]['G'][e])
        a[cl] = torch.from_numpy(np.array(x1).reshape(-1,7))
        realdata.extend(x1)
    realdata = torch.from_numpy(np.array(realdata).reshape(-1,7))   
    return realdata

class Batch_Net(nn.Module):
    """
    On the basis of Activation_Net above, a method to speed up the convergence speed is added - batch normalization
    """

    def __init__(self, in_dim, n_hidden_1, n_hidden_2, n_hidden_3, n_hidden_4, n_hidden_5, out_dim):
        super(Batch_Net, self).__init__()
        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1), nn.ReLU(True))
        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2), nn.ReLU(True))
        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, n_hidden_3), nn.BatchNorm1d(n_hidden_3), nn.Dropout(p=0.5))
        self.layer4 = nn.Sequential(nn.Linear(n_hidden_3, n_hidden_4), nn.BatchNorm1d(n_hidden_4), nn.ReLU(True))
        self.layer5 = nn.Sequential(nn.Linear(n_hidden_4, n_hidden_5), nn.BatchNorm1d(n_hidden_5), nn.ReLU(True))
        self.layer6 = nn.Sequential(nn.Linear(n_hidden_5, out_dim))

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.layer5(x)
        x = self.layer6(x)
        return x

# Decide which device we run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")
#join: instantiate
Forward_net=Batch_Net(124, 200, 250, 250, 250, 200, 3)
#Extract the entire forward prediction network
Forward_net = torch.load('./Inverse_Design_1_Laser/net_newall_445+520+634_200_5.27.pkl').to(device)
#network
#In the discrimination part, it is judged whether the data generated by the generator conforms to the range, and if so, it is thrown into the fully connected prediction network to predict the G value; if not, a false G value is given
def distinguish(input_data):
    data = torch.empty_like(input_data)
    real_input = torch.empty(batch_size,124)
    for j in range(0,batch_size):
        data[j][0]=inverse_minmaxscaler(input_data[j][0],NColors,1)
        data[j][1]=inverse_minmaxscaler(input_data[j][1],thick_max,thick_min)
        data[j][2]=inverse_minmaxscaler(input_data[j][2],str_max,str_min)
        data[j][3]=inverse_minmaxscaler(input_data[j][3],gra_max,gra_min)
        complete_data=data_transform(data[j])
        complete_data_norm=norm(complete_data)
        real_input[j] = torch.squeeze(complete_data_norm)
    return Forward_net(real_input.to(device))

#If the condition is met, it will return 0, if not, it will return the distance; F.relu: If it is less than 0, it will be truncated to 0
#The final control condition is always between 0 and 1.
def my_loss(input_data):
    # In the dimension of dim, sum the tesnor inside
    err = torch.sum(F.relu(-input_data)+F.relu(input_data-1))+torch.sum(torch.abs(input_data[:,0]-7/9.0))+torch.sum(torch.abs(input_data[:,2]-145/247.0))#限制颜色为7号颜色blue6,限制拉伸程度为167%
    return err

#weight initialization
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

                  
#build generator
class Generator(nn.Module):
    def __init__(self, ngpu):
        self.ngpu = ngpu
        super(Generator, self).__init__()
        self.data = nn.Sequential(
            nn.Linear(G_IN_din, 40),
            nn.LazyBatchNorm1d(),
            nn.ReLU(True),
            nn.Linear(40, 80),
            nn.LazyBatchNorm1d(),
            nn.ReLU(True),
            nn.Linear(80, 20),
            nn.LazyBatchNorm1d(),
            nn.ReLU(True),
            nn.Linear(20,4)
        )

    def forward(self, x):
        x = self.data(x)
        return x

# create generator
netG = Generator(ngpu).to(device)

# If you want to use multiple GPUs, set it.
if (device.type == 'cuda') and (ngpu > 1):
    netG = nn.DataParallel(netG, list(range(ngpu)))

# Use the weight initialization function weights_init to randomly initialize all weights
netG.apply(weights_init)

#read data
realdata=getData1('./Data/sdb.msgz')#data file path
# #Divide the dataset
data0=realdata[:,:4]#four conditions
data1=realdata[:,4:]
train_data, test_data, target_train_data, target_test_data = train_test_split(data0, data1, test_size=0.05, random_state=888)#Randomly fetch data
trans_data = scaler.fit_transform(data0)# Standardize the data to ensure that the variance of the feature data in each dimension is 1 and the mean is 0, so that the prediction results will not be dominated by feature values that are too large in some dimensions
dataloader = torch.utils.data.DataLoader(dataset=realdata, batch_size=batch_size, shuffle=True,drop_last=True)
#Optimizer and loss function
# Initialize BCELoss function  
criterion = nn.MSELoss(reduction='mean')

# Setup Adam optimizers for both G and D
optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))



#Color Number: Red Green Blue, 123
def colorData(dye_property_file):
    dye_property = sp.read_file(dye_property_file)
    color_dict={}#Store 121 parameters corresponding to the color
    j=1
    for cl in Color_Values:
        color_dict[j] = [] #Store 121 pigment characteristic absorption spectrum data
        color_last=len(dye_property[cl])#Pick out 121 data
        color_step=int(len(dye_property[cl])/120)
        for i in range(0,color_last,color_step):  #Different colors have different amounts of data
            color_dict[j].append(dye_property[cl][i][1])
        j+=1
    return color_dict

color_dict=colorData('./Data/dye_prop.msgz')
#Color data changed from 1 to 121
def color_transform(data):
    l=121
    lis=[0.0 for _ in range(l)]
    colornum=torch.round(data).item()
    if colornum in range(1, NColors+1):
        return color_dict[colornum]
    else:
        return lis
        
#Color Number: Red Green Blue, 123
def colorMatrix(dye_property_file):
    dye_property = sp.read_file(dye_property_file)
    color_matrix=[]#Store 121 parameters corresponding to the color
    j=1
    for cl in Color_Values:
        color_info = [] #Store 121 pigment characteristic absorption spectrum data
        color_last=len(dye_property[cl])#Pick out 121 data
        color_step=int(len(dye_property[cl])/120)
        for i in range(0,color_last,color_step):  #Different colors have different amounts of data
            color_info.append(dye_property[cl][i][1])
        color_matrix.append(color_info)
        j+=1
    return torch.tensor(color_matrix,dtype=torch.float32)

color_matrix=colorMatrix('./Data/dye_prop.msgz').to(device)
#Color data changed from 1 to 121
def color_transform2(color):
    color_labels=torch.from_numpy(np.arange(1.0,NColors+1.0,dtype=np.float32)).to(device)
    color_distance = F.relu(1.0-torch.abs(color_labels-color))
    color_onehot = F.softmax(color_distance*20, 0)
    return torch.matmul(color_onehot.reshape(1,-1),color_matrix)
    
#The total data changed from 4 to 124, and normalized at the same time
def data_transform(data):
    clist=torch.squeeze(color_transform2(data[0]))
    data1=torch.flatten(torch.cat((clist,data[1:]),0))
    return data1

def norm(data):    
    #Globally normalize colors
    color_x=data[:-3]#One-dimensional color data
    color_x=minmaxscaler(color_x,col_max,col_min)
    color_x=torch.unsqueeze(color_x,0)
    #Column-wise normalization for the other three parameters
    thick_x=minmaxscaler(data[-3],thick_max,thick_min)
    thick_x=torch.unsqueeze(torch.unsqueeze(thick_x,0),0)
    str_x=minmaxscaler(data[-2],str_max,str_min)
    str_x=torch.unsqueeze(torch.unsqueeze(str_x,0),0)
    gra_x=minmaxscaler(data[-1],gra_max,gra_min)
    gra_x=torch.unsqueeze(torch.unsqueeze(gra_x,0),0)
    x_un=torch.cat([color_x,thick_x,str_x,gra_x],dim=1)
    return x_un
#train
# Lists to keep track of progress  
img_list = []
G_losses = []
D_losses = []
D_x_list = []
D_z_list = []

print("Starting Pre Training Loop...")
# For each epoch  

for i, data in enumerate(dataloader,0):
    optimizerG.zero_grad()
    real_G=data[:,4:]
    b_size=real_G.size(0)
    noise = torch.randn(b_size, G_IN_din, device=device)
    fake = netG(noise)
    err_New = my_loss(fake)
    err_New.backward()
    optimizerG.step()
    print(
        f'Step: [{i+1:0>{len(str(len(dataloader)))}}/{len(dataloader)}]',
        f'Loss-New: {err_New.item():.4f}',
        end='\r'
    )

print("Starting Real Training Loop...")
for epoch in range(num_epochs):
    beg_time = time.time()#Returns the timestamp of the current time
    for i, data in enumerate(dataloader,0):
        optimizerG.zero_grad()
        # ideal_Gvalue=0.5
        ideal_dif=gdif
        real_G=data[:,4:]
        b_size=real_G.size(0)
        noise = torch.randn(b_size, G_IN_din, device=device)
        fake = netG(noise)#fake is the discriminator input
        # Since we just updated D, perform another forward pass of all-fake batch through D
        output = distinguish(fake)#The output of the discriminator is an n*121 array
        # # Calculate G's loss based on this output   
        err_New = my_loss(fake)
        err_New.backward(retain_graph=True)
        # wave1_g,wave2_g=Cor_wave(output)
        wave1_g =output[:,0]#Corresponding to 447nm
        wave2_g =output[:,1]#Corresponding to 520nm
        Gdif=torch.abs(wave1_g-wave2_g)
        idaeldif=torch.full((b_size,), ideal_dif, device=device)
        idaeldif=idaeldif.to(torch.float32)
        errdif= criterion(idaeldif,Gdif)
        errdif.backward()
        # Update G   
        optimizerG.step()
        # Output training stats 
        end_time = time.time()
        run_time = round(end_time-beg_time)
        print(
            f'Epoch: [{epoch+1:0>{len(str(num_epochs))}}/{num_epochs}]',
            f'Step: [{i+1:0>{len(str(len(dataloader)))}}/{len(dataloader)}]',
            f'Loss-New: {err_New.item():.4f}',
            f'Loss-dif: {errdif.item():.4f}',
            f'Time: {run_time}s',
            end='\r'
        )
        # Save Losses for plotting later 
        G_losses.append(err_New.item())
        D_losses.append(errdif.item())
        # D_z_list.append(D_G_z)

# Create batch of latent vectors and laebls that we will use to visualize the progression of the generator
fixed_noise = torch.randn(1000, 4).to(device)
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="New")
plt.plot(D_losses,label="Dif")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

torch.save(netG, './Inverse_Design_1_Laser/%g+%g/netG_all_%g+%g.pkl'%(wave1,wave2,wave1,wave2))

def data_in_range(d):
    return (NColors>=d[0]>=1 and thick_max>=d[1]>=thick_min and str_max>=d[2]>=str_min and gra_max>=d[3]>=gra_min)
# Get a batch of real images from the dataloader
right=[]
net_G_data=[]
loss_G_data=[]
gan_G_data=[]
h=[]
news_list = []
real_batch = next(iter(dataloader))
noise1 = torch.randn(4000, G_IN_din, device=device)
result_data=netG(noise1)
# print(result_data)
result_size=result_data.size(0)
for j in range(0,result_size):
    result_data[j][0]=inverse_minmaxscaler(result_data[j][0],NColors,1)
    result_data[j][1]=inverse_minmaxscaler(result_data[j][1],thick_max,thick_min)
    result_data[j][2]=inverse_minmaxscaler(result_data[j][2],str_max,str_min)
    result_data[j][3]=inverse_minmaxscaler(result_data[j][3],gra_max,gra_min)
    # if torch.round(result_data[j][0]).to(torch.float64)==1.0 and torch.round(result_data[j][1]).to(torch.float64)==48.0:#and torch.round(result_data[j][2]).to(torch.float64)==133.0
    if data_in_range(result_data[j]):
        complete_data=data_transform(result_data[j])
        complete_data_norm=norm(complete_data)
        net_G=Forward_net(complete_data_norm)
        wave1_g=net_G[:,0]
        wave2_g=net_G[:,1]
        dif=torch.abs(wave1_g-wave2_g)
        adata=np.around(result_data[j].detach().numpy())
        if dif>=2.0:
            print('条件：'+str(adata)+'\n'+'%g nm: '%(wave1)+str(wave1_g.item())+'\n'+'%g nm：'%(wave2)+str(wave2_g.item())+'\n'+'两波长对应G值差：'+str(dif.item())+'\n')
            h.append(adata)
            with open('./Inverse_Design_1_Laser/%g+%g/%g+%g_g%g.csv'%(wave1,wave2,wave1,wave2,gdif),'a',newline="") as f:
                writer = csv.writer(f)
                writer.writerow(result_data[j].detach().numpy().tolist())
print(np.array(list(set([tuple(t) for t in h]))))


